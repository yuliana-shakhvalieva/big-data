{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "038bdee5",
   "metadata": {},
   "source": [
    "## Блок 1. Standalone Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c570e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c7c04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder.appName('spark-standalone-cluster')\\\n",
    "    .master('spark://DESKTOP-FBH5D4M.:7077')\\\n",
    "    .config('spark.driver.memory', '4g')\\\n",
    "    .config('spark.driver.cores', '4')\\\n",
    "    .config('spark.executor.memory', '4g')\\\n",
    "    .config('spark.executor.cores', '4')\\\n",
    "    .config('spark.cores.max', '8')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de087c",
   "metadata": {},
   "source": [
    "## Блок 2. Работа с данными на Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cafc702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset_book/book1000k-1100k.csv\n",
      "(97997, 20)\n",
      "./dataset_book/book100k-200k.csv\n",
      "(155043, 20)\n",
      "./dataset_book/book1100k-1200k.csv\n",
      "(196935, 20)\n",
      "./dataset_book/book1200k-1300k.csv\n",
      "(240557, 20)\n",
      "./dataset_book/book1300k-1400k.csv\n",
      "(278845, 20)\n",
      "./dataset_book/book1400k-1500k.csv\n",
      "(313604, 20)\n",
      "./dataset_book/book1500k-1600k.csv\n",
      "(347043, 20)\n",
      "./dataset_book/book1600k-1700k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380029, 20)\n",
      "./dataset_book/book1700k-1800k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412134, 20)\n",
      "./dataset_book/book1800k-1900k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450997, 20)\n",
      "./dataset_book/book1900k-2000k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494558, 20)\n",
      "./dataset_book/book2000k-3000k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(890515, 20)\n",
      "./dataset_book/book200k-300k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(946697, 20)\n",
      "./dataset_book/book3000k-4000k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1203292, 20)\n",
      "./dataset_book/book300k-400k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1259878, 20)\n",
      "./dataset_book/book4000k-5000k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1540134, 20)\n",
      "./dataset_book/book400k-500k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1595289, 20)\n",
      "./dataset_book/book500k-600k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650148, 20)\n",
      "./dataset_book/book600k-700k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1705304, 20)\n",
      "./dataset_book/book700k-800k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1759577, 20)\n",
      "./dataset_book/book800k-900k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1809420, 20)\n",
      "./dataset_book/book900k-1000k.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1566:===================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1850310, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = './dataset_book/*.csv'\n",
    "files = glob.glob(file_path)\n",
    "\n",
    "df = spark.read.options(quote=\"\\\"\", escape=\"\\\"\", multiLine=True, header=True, inferSchema=True).csv(files[0])\n",
    "\n",
    "for file in files[1:]:\n",
    "    print(file)\n",
    "    df_current = spark.read.options(quote=\"\\\"\", escape=\"\\\"\", multiLine=True,header=True, inferSchema=True).csv(file)\n",
    "    df = df.unionByName(df_current, allowMissingColumns=True)\n",
    "    print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bf66b3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- RatingDist1: string (nullable = true)\n",
      " |-- pagesNumber: integer (nullable = true)\n",
      " |-- RatingDist4: string (nullable = true)\n",
      " |-- RatingDistTotal: string (nullable = true)\n",
      " |-- PublishMonth: integer (nullable = true)\n",
      " |-- PublishDay: integer (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- CountsOfReview: integer (nullable = true)\n",
      " |-- PublishYear: integer (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Authors: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- RatingDist2: string (nullable = true)\n",
      " |-- RatingDist5: string (nullable = true)\n",
      " |-- ISBN: string (nullable = true)\n",
      " |-- RatingDist3: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Count of text reviews: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "06618c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"Count of text reviews\",\"Count_of_text_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv('./dataset_book/data_csv', header=True)\n",
    "df.write.parquet('./dataset_book/data_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e3b87acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read.csv('./dataset_book/data_csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe00c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.parquet('./dataset_book/data_parquet', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "67787f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1653:=================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----------+-----------+-----------+---------------+------------+----------+---------+--------------+-----------+--------+-------+------+-----------+-----------+----+-----------+-----------+---------------------+\n",
      "| Id|Name|RatingDist1|pagesNumber|RatingDist4|RatingDistTotal|PublishMonth|PublishDay|Publisher|CountsOfReview|PublishYear|Language|Authors|Rating|RatingDist2|RatingDist5|ISBN|RatingDist3|Description|Count_of_text_reviews|\n",
      "+---+----+-----------+-----------+-----------+---------------+------------+----------+---------+--------------+-----------+--------+-------+------+-----------+-----------+----+-----------+-----------+---------------------+\n",
      "|  0|   0|          0|          0|          0|              0|           0|         0|    17824|             0|          0| 1598488|      1|     0|          0|          0|5923|          0|     679070|              1440613|\n",
      "+---+----+-----------+-----------+-----------+---------------+------------+----------+---------+--------------+-----------+--------+-------+------+-----------+-----------+----+-----------+-----------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parquet.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_parquet.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e7d754",
   "metadata": {},
   "source": [
    "#### Топ-10 книг с наибольшим числом ревью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f9bdbdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1651:>                                                       (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|                Name|CountsOfReview|\n",
      "+--------------------+--------------+\n",
      "|The Hunger Games ...|        154447|\n",
      "|Twilight (Twiligh...|         94850|\n",
      "|      The Book Thief|         87685|\n",
      "|            The Help|         76040|\n",
      "|Harry Potter and ...|         75911|\n",
      "|The Giver (The Gi...|         57034|\n",
      "| Water for Elephants|         52918|\n",
      "|The Girl with the...|         52225|\n",
      "|Harry Potter and ...|         52088|\n",
      "|The Lightning Thi...|         48630|\n",
      "+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parquet\\\n",
    "    .select(\"Name\", \"CountsOfReview\")\\\n",
    "    .orderBy(desc('CountsOfReview'))\\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82f55c",
   "metadata": {},
   "source": [
    "#### Топ-10 издателей с наибольшим средним числом страниц в книгах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e3cf7120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1656:===========================>                        (106 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|           Publisher|  avg(pagesNumber)|\n",
      "+--------------------+------------------+\n",
      "|Crafty Secrets Pu...|         1807321.6|\n",
      "|    Sacred-texts.com|          500000.0|\n",
      "|Department of Rus...| 322128.5714285714|\n",
      "|Logos Research Sy...|          100000.0|\n",
      "|Encyclopedia Brit...|           32642.0|\n",
      "|Progressive Manag...|        19106.3625|\n",
      "|Still Waters Revi...|10080.142857142857|\n",
      "|P. Shalom Publica...|            8539.0|\n",
      "|Hendrickson Publi...|            6448.0|\n",
      "|            IEEE/EMB|            6000.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parquet\\\n",
    "    .select('Publisher', 'pagesNumber')\\\n",
    "    .groupBy('Publisher').avg('pagesNumber')\\\n",
    "    .orderBy(desc('avg(pagesNumber)'))\\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5aa93e",
   "metadata": {},
   "source": [
    "#### Десять наиболее активных по числу изданных книг лет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9dac4049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1657:=================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|PublishYear| count|\n",
      "+-----------+------+\n",
      "|       2007|129507|\n",
      "|       2006|122374|\n",
      "|       2005|117639|\n",
      "|       2004|105733|\n",
      "|       2003|104345|\n",
      "|       2002| 95537|\n",
      "|       2001| 88228|\n",
      "|       2000| 87290|\n",
      "|       2008| 80265|\n",
      "|       1999| 80155|\n",
      "+-----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parquet\\\n",
    "    .select('PublishYear')\\\n",
    "    .groupBy('PublishYear')\\\n",
    "    .count()\\\n",
    "    .orderBy(desc('count'))\\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0fbf62",
   "metadata": {},
   "source": [
    "#### Топ-10 книг имеющих наибольший разброс в оценках среди книг имеющих больше 500 оценок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b230ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev\n",
    "\n",
    "def calculate_stdev(row):\n",
    "    data = [float(x[2:].strip()) for x in row.split(\",\")]\n",
    "    return stdev(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8c520a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev_udf = udf(calculate_stdev, FloatType())\n",
    "df_parquet = df_parquet.withColumn('StdDev', std_dev_udf(concat_ws(\",\",\\\n",
    "                                                        df_parquet.RatingDist1,\\\n",
    "                                                        df_parquet.RatingDist2,\\\n",
    "                                                        df_parquet.RatingDist3,\\\n",
    "                                                        df_parquet.RatingDist4,\\\n",
    "                                                        df_parquet.RatingDist5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "19d8b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = df_parquet\\\n",
    "    .withColumn('Total', \\\n",
    "                expr(\"substring(RatingDistTotal, 7, length(RatingDistTotal)-7)\").\\\n",
    "                cast('Integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8771c4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1659:=================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------+\n",
      "|                Name|   StdDev| Total|\n",
      "+--------------------+---------+------+\n",
      "|Ο Χάρι Πότερ και ...|1884481.0|709468|\n",
      "|Harry Potter og D...|1857551.5|699559|\n",
      "|Harry Potter e a ...|1856879.5|699315|\n",
      "|Harry Potter and ...|1850987.2|697097|\n",
      "|Harry Potter och ...|1833126.8|690522|\n",
      "|Harry Potter och ...|1824451.8|687169|\n",
      "|Harry Potter e a ...|1822858.0|686591|\n",
      "|Harry Potter and ...|1815587.4|683920|\n",
      "|Harry Potter i Ka...|1814183.4|683396|\n",
      "|Harri Potter maen...|1811594.9|682464|\n",
      "+--------------------+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parquet\\\n",
    "    .select('Name', 'StdDev', 'Total')\\\n",
    "    .where('Total > 500' )\\\n",
    "    .orderBy(desc('StdDev'))\\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0061f10d",
   "metadata": {},
   "source": [
    "#### Любой интересный инсайт из данных: cредний рейтинг по годам выпуска за последние 10 лет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1931215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 680:======================>                              (85 + 10) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|PublishYear|       avg(Rating)|\n",
      "+-----------+------------------+\n",
      "|       2022|              3.89|\n",
      "|       2021|0.9221276595744682|\n",
      "|       2020|  2.53327868852459|\n",
      "|       2019|2.6745007923930273|\n",
      "|       2018|2.7876787372330547|\n",
      "|       2017| 2.431105463786531|\n",
      "|       2016|2.5692142188961653|\n",
      "|       2015| 2.692784277023865|\n",
      "|       2014|2.5914216163583252|\n",
      "|       2013|2.7313730355665844|\n",
      "+-----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parquet\\\n",
    "    .select('PublishYear', 'Rating')\\\n",
    "    .where('PublishYear <= 2023')\\\n",
    "    .groupBy('PublishYear')\\\n",
    "    .avg('Rating')\\\n",
    "    .orderBy(desc('PublishYear'))\\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f63b74",
   "metadata": {},
   "source": [
    "## Блок 3. Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a891f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"ID\", IntegerType(), True),\n",
    "                     StructField(\"Name\", StringType(), True),\n",
    "                     StructField(\"Rating\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "646e366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = spark\\\n",
    "            .readStream\\\n",
    "            .option(\"quote\", \"\\\"\")\\\n",
    "            .option(\"escape\", \"\\\"\")\\\n",
    "            .schema(schema)\\\n",
    "            .csv('./dataset_user_rating/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "857f1d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/16 22:51:00 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-c53de093-2f0b-4706-b9fc-bd398c4c0585. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+--------------------+------+\n",
      "|              Rating| count|\n",
      "+--------------------+------+\n",
      "|     did not like it|  7811|\n",
      "|              Rating|     7|\n",
      "|     really liked it|132808|\n",
      "|            liked it| 96047|\n",
      "|           it was ok| 28811|\n",
      "|      it was amazing| 92354|\n",
      "|This user doesn't...|  4765|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rating = streaming.groupBy('Rating').count()\n",
    "active_query = rating.writeStream.format('console').outputMode('complete').start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed14d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    if x == 'it was amazing':\n",
    "        return 5\n",
    "    elif x == 'really liked it':\n",
    "        return 4\n",
    "    elif x == 'liked it':\n",
    "        return 3\n",
    "    elif x == 'it was ok':\n",
    "        return 2\n",
    "    elif x == 'did not like it':\n",
    "        return 1\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "011f00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "time = datetime.datetime.now()\n",
    "\n",
    "def add_time():\n",
    "    global time\n",
    "    time += timedelta(seconds=60)\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69aeb4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "streaming.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a205743d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/16 22:54:13 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-609fd031-847f-4e4c-b9bf-c6c88ef799e3. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fe565db2340>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/16 22:54:17 WARN FileStreamSource: Listed 7 file(s) in 2594 ms            \n",
      "23/04/16 22:54:19 WARN FileStreamSource: Listed 7 file(s) in 2101 ms            \n",
      "23/04/16 22:54:21 WARN FileStreamSource: Listed 7 file(s) in 2116 ms            \n",
      "23/04/16 22:54:24 WARN FileStreamSource: Listed 7 file(s) in 2990 ms            \n",
      "23/04/16 22:54:30 WARN FileStreamSource: Listed 7 file(s) in 3456 ms            \n",
      "23/04/16 22:54:43 WARN FileStreamSource: Listed 7 file(s) in 8511 ms            \n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def foreach_batch_function(df, epoch_id):\n",
    "    convUDF = udf(convert, IntegerType())\n",
    "    df = df.withColumn('Int_rating', convUDF('Rating'))\n",
    "    \n",
    "    convUDF_1 = udf(add_time, TimestampType())\n",
    "    df = df.withColumn('Time', convUDF_1())\n",
    "    \n",
    "    windowed = df\\\n",
    "            .withWatermark(\"time\", \"20000 milliseconds\")\\\n",
    "            .groupBy(window(\"time\", \"10 seconds\"), \"Name\")\\\n",
    "            .agg(avg(\"Int_rating\").alias('avg_rating'))\n",
    "\n",
    "    windowed.write.parquet('./dataset_user_rating/parquet')\n",
    "    \n",
    "streaming.writeStream.foreachBatch(foreach_batch_function).start()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "39860c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x7fe565e97e80>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x7fe565e976d0>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21acf2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.streams.active[0].stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3b10fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.parquet('./dataset_user_rating/parquet', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0f3a3158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|              window|                Name|avg_rating|\n",
      "+--------------------+--------------------+----------+\n",
      "|{2023-04-17 01:49...|Don't Make Me Thi...|       4.0|\n",
      "|{2023-04-17 02:27...| The Grapes of Wrath|       3.0|\n",
      "|{2023-04-17 06:23...|Ender's Game (End...|       5.0|\n",
      "|{2023-04-17 09:07...|           Amsterdam|       5.0|\n",
      "|{2023-04-17 09:12...|The Flame Trees o...|       5.0|\n",
      "|{2023-04-17 12:49...|The Sword in the ...|       4.0|\n",
      "|{2023-04-18 04:09...|Abstract Expressi...|       5.0|\n",
      "|{2023-04-18 07:39...|Zero to One: Note...|       4.0|\n",
      "|{2023-04-18 08:55...|  Eaters of the Dead|       4.0|\n",
      "|{2023-04-18 10:46...|It's Not How Good...|       5.0|\n",
      "|{2023-04-18 16:47...|      I Know My Name|       3.0|\n",
      "|{2023-04-18 18:18...|Fist Stick Knife ...|       5.0|\n",
      "|{2023-04-18 23:41...|Divine Secrets Of...|       3.0|\n",
      "|{2023-04-18 23:57...|        The Namesake|       3.0|\n",
      "|{2023-04-19 00:27...|   The Secret Garden|       5.0|\n",
      "|{2023-04-19 01:28...|Emotional Intelli...|       4.0|\n",
      "|{2023-04-19 03:10...|The Big Thirst: T...|       4.0|\n",
      "|{2023-04-19 18:30...|           Here I Am|       4.0|\n",
      "|{2023-04-19 22:45...|Olivia's Vacation...|       5.0|\n",
      "|{2023-04-19 23:19...|Beautiful Code: L...|       3.0|\n",
      "+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parquet.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
